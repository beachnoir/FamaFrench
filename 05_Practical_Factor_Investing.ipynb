{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79279422",
   "metadata": {},
   "source": [
    "# Practical Factor Investing: Dimensional, Avantis, and Portfolio Construction\n",
    "\n",
    "## From Theory to Practice — Analysing Real Factor ETFs with the Tools We've Built\n",
    "\n",
    "---\n",
    "\n",
    "### Where This Fits\n",
    "\n",
    "This is the fifth notebook in the series. The recommended reading order is:\n",
    "\n",
    "1. **[Statistical Foundations](01_Statistical_Foundations.ipynb)** — CLT, hypothesis testing, OLS, sandwich estimators, Newey-West derivation\n",
    "2. **[Time Series Foundations](02_Time_Series_Foundations.ipynb)** — Stationarity, autocorrelation, volatility clustering, ergodicity\n",
    "3. **[Fama-French 3-Factor Model](03_Fama_French_3Factor.ipynb)** — Data, regression mechanics, diagnostics, robust SEs, interpretation\n",
    "4. **[Advanced Factor Models](04_Advanced_Factor_Models.ipynb)** — FF5, momentum, profitability, beta anomaly, Chen's challenge, rolling windows\n",
    "5. **Practical Factor Investing** — this notebook\n",
    "\n",
    "The previous notebooks gave us the *theory*, the *statistical tools*, and the *research landscape*. This notebook asks: **how do real-world fund managers translate factor research into investable products — and can we verify their claims using the methods we've learned?**\n",
    "\n",
    "### What We'll Cover\n",
    "\n",
    "1. **The Dimensional and Avantis Investment Philosophies** — How these firms implement academic factor research, their scientific approach, and what distinguishes them from traditional index funds\n",
    "2. **Data: Avantis UCITS ETFs on Xetra** — Loading daily return data for AVWS, AVWC, and AVEM alongside global Fama-French factors\n",
    "3. **Descriptive Analysis** — Return distributions, volatility, drawdowns, and how these ETFs compare\n",
    "4. **Factor Regression Analysis** — Applying FF5 + Momentum regressions to identify each ETF's factor exposures, with full diagnostic checks\n",
    "5. **Comparative Factor Profiles** — Visualising how the ETFs differ in their factor tilts and what that implies\n",
    "6. **Portfolio Construction** — Building a 50% AVWS / 40% AVWC / 10% AVEM portfolio and analysing its risk-return characteristics\n",
    "7. **Portfolio Factor Analysis** — Running factor regressions on the combined portfolio\n",
    "8. **Limitations and Conclusions** — What we can and cannot conclude from limited data\n",
    "\n",
    "### A Note on Data Limitations\n",
    "\n",
    "> **Important caveat (March 2026):** The Avantis UCITS ETFs launched on European exchanges in late 2024. We have approximately **17 months of daily data** for AVWS and AVWC, and roughly **15 months** for AVEM. This is a *very* short sample for drawing definitive conclusions about factor exposures and alpha.\n",
    ">\n",
    "> What we **can** do with daily data:\n",
    "> - Identify factor **tilts** (betas) with reasonable statistical precision — 300+ daily observations gives enough power for point estimates\n",
    "> - Characterise the return distribution and risk profile\n",
    "> - Illustrate how the analytical tools from earlier notebooks apply to real portfolios\n",
    ">\n",
    "> What we **cannot** do reliably:\n",
    "> - Estimate alpha with tight confidence intervals\n",
    "> - Draw conclusions about long-term performance\n",
    "> - Compare realised premia to historical averages (the sample is too short)\n",
    ">\n",
    "> This notebook is therefore as much a **methodology demonstration** as a performance evaluation. The tools we apply here will remain valid as the data history grows.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "All four preceding notebooks. We use:\n",
    "- **OLS regression with Newey-West standard errors** ([Notebook 1, Section 7](01_Statistical_Foundations.ipynb))\n",
    "- **Autocorrelation and volatility clustering diagnostics** ([Notebook 2, Sections 3-4](02_Time_Series_Foundations.ipynb))\n",
    "- **Factor regression mechanics and interpretation** ([Notebook 3](03_Fama_French_3Factor.ipynb))\n",
    "- **The FF5 + Momentum model and its interpretation** ([Notebook 4, Sections 1-2](04_Advanced_Factor_Models.ipynb))\n",
    "- **The DFA/Avantis implementation philosophy** ([Notebook 4, Section 6](04_Advanced_Factor_Models.ipynb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8fe2be",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 1: The Dimensional and Avantis Investment Philosophies\n",
    "\n",
    "### 1.1 Dimensional Fund Advisors — The Original Factor Firm\n",
    "\n",
    "Dimensional was founded in 1981 by David Booth and Rex Sinquefield, with direct guidance from Eugene Fama and Kenneth French (who serve as consultants and board members). Having crossed $1 trillion USD in AUM, Dimensional is the largest firm built entirely on academic factor research.\n",
    "\n",
    "**Core Investment Philosophy:**\n",
    "- Markets are broadly efficient — don't try to pick stocks or time the market\n",
    "- Academic research identifies **reliable dimensions of higher expected returns**: market, size, value, and profitability\n",
    "- **Systematically tilt** portfolios toward small-cap, value, and profitable stocks\n",
    "- Use **patient, low-cost trading** — don't track an index mechanically, but trade opportunistically to minimise costs\n",
    "- **Broad diversification** within the tilt — hold thousands of stocks, not concentrated bets\n",
    "\n",
    "**The Integrated Approach (from Wei Dai, Rational Reminder Episode 306):**\n",
    "\n",
    "As discussed in [Notebook 4, Section 6.4](04_Advanced_Factor_Models.ipynb), Dimensional's key innovation is the **integrated multi-factor portfolio**. Rather than buying separate value, size, and profitability funds (the \"combination\" approach) or adding a concentrated factor satellite to a core holding, DFA does a **three-way simultaneous sort** on size, value, and profitability:\n",
    "\n",
    "- Start with the entire market\n",
    "- Score every stock on all three dimensions at once\n",
    "- Gradually shift weight toward stocks with higher expected returns across *all* dimensions\n",
    "- Use a **multiplier system**: each stock's weight = market-cap weight x multiplier (e.g., 2x for high-expected-return segments, 0.5x for low)\n",
    "\n",
    "This avoids the problem identified by Novy-Marx ([Notebook 4, Section 6.9](04_Advanced_Factor_Models.ipynb)): buying a value fund and a profitability fund separately can **cancel out** factor exposures, because value stocks tend to score low on profitability and vice versa.\n",
    "\n",
    "**Key Implementation Details:**\n",
    "- **No hard rebalancing dates** — daily rebalancing ranges instead of quarterly index reconstitution\n",
    "- **Momentum as an exclusion screen** — delay buying stocks with negative momentum (avoids \"catching falling knives\")\n",
    "- **Reversal screens** — based on Dai & Novy-Marx (2024), delay trading when short-term reversals suggest adverse selection\n",
    "- **8,000–12,000 stocks** per portfolio — extreme diversification to capture Bessembinder's insight that only 4% of stocks drive all wealth creation ([Notebook 4, Section 6.5](04_Advanced_Factor_Models.ipynb))\n",
    "\n",
    "**Dimensional UCITS ETFs:**\n",
    "Dimensional launched UCITS-compliant ETFs for European investors, including DEGC (Global Core Equity) and DEGT (Global Targeted Value). However, these launched only in late 2025, making their data history too short for meaningful statistical analysis at this time.\n",
    "\n",
    "### 1.2 Avantis Investors — The Scientific Approach\n",
    "\n",
    "Avantis was founded in 2019 by Eduardo Repetto (former CIO of Dimensional) and a team of ex-DFA researchers. Their approach builds on the Dimensional foundation but introduces several refinements.\n",
    "\n",
    "**The \"Scientific Approach to Investing\"**\n",
    "\n",
    "Avantis' investment philosophy, as outlined in their institutional research documents, rests on three pillars:\n",
    "\n",
    "**Pillar 1: Markets Are Broadly Efficient, But Expected Returns Vary**\n",
    "- Security prices reflect available information quickly and accurately *most of the time*\n",
    "- However, expected returns are **not equal across all stocks** — some characteristics (value, profitability) are associated with higher expected returns\n",
    "- This is not a contradiction: efficient markets can still offer different expected returns as compensation for different levels of risk\n",
    "\n",
    "**Pillar 2: Identify Reliable Drivers of Expected Returns**\n",
    "- Use economic theory and empirical evidence to identify characteristics that predict cross-sectional return differences\n",
    "- Focus on characteristics that are: (a) persistent across time, (b) pervasive across markets, (c) robust to different measurement approaches, (d) grounded in economic intuition\n",
    "- Avantis focuses on two primary signals:\n",
    "  - **Valuation ratios** (book-to-market, earnings yield) — the value dimension\n",
    "  - **Cash-flow-based profitability** — the profitability dimension\n",
    "- These are combined into a single **composite expected return** score for each stock\n",
    "\n",
    "**Pillar 3: Thoughtful Portfolio Construction Minimises Costs**\n",
    "- The gap between theoretical factor returns and realisable returns is large (as Chen & Velikov documented — [Notebook 4, Section 7](04_Advanced_Factor_Models.ipynb))\n",
    "- Avantis explicitly designs portfolios to **minimise the implementation shortfall**:\n",
    "  - Broad diversification (thousands of holdings)\n",
    "  - Integrated multi-factor sorting (not separate factor sleeves)\n",
    "  - Patient, spread-sensitive trading\n",
    "  - Momentum and reversal signals used to **time trades**, not as standalone factors\n",
    "\n",
    "**Key Differences from Dimensional:**\n",
    "\n",
    "| Dimension | Dimensional | Avantis |\n",
    "|-----------|-------------|---------|\n",
    "| **Sorting method** | Independent sorts on size × value × profitability, then multiplier weights | Composite expected-return score combining value + profitability |\n",
    "| **Philosophy** | Three-way sort with gradual tilts | Rank all stocks by expected return, overweight the top |\n",
    "| **Concentration** | Very broad (8,000–12,000 stocks) | Somewhat more concentrated (still thousands of stocks) |\n",
    "| **Distribution** | Historically advisor-only; now also ETFs | ETF-first from launch |\n",
    "| **Momentum use** | Exclusion screen only (avoid negative momentum) | Timing signal for trade execution |\n",
    "| **Fee structure** | Competitive (0.15–0.35%) | Very competitive (0.15–0.25%) |\n",
    "\n",
    "**The Avantis UCITS ETFs We'll Analyse:**\n",
    "\n",
    "| Ticker | Full Name | Strategy | Launch (Xetra) |\n",
    "|--------|-----------|----------|-----------------|\n",
    "| **AVWS** | Avantis Global Small Cap Value UCITS ETF | Small-cap stocks screened for value + profitability worldwide | October 2024 |\n",
    "| **AVWC** | Avantis Global Equity UCITS ETF | All-cap global equity with value + profitability tilts | October 2024 |\n",
    "| **AVEM** | Avantis Emerging Markets Equity UCITS ETF | EM equity with value + profitability tilts | December 2024 |\n",
    "\n",
    "**What we expect to find in factor regressions:**\n",
    "- **AVWS**: Positive SMB (small-cap), positive HML (value tilt), positive RMW (profitability screen). This should look like a small-cap value fund with a profitability overlay.\n",
    "- **AVWC**: Market beta close to 1, modest positive HML and RMW (broad market with gentle tilts). Should resemble a \"market-plus\" strategy.\n",
    "- **AVEM**: Market beta near 1 for EM, with positive HML and RMW. May show different factor loadings due to EM-specific characteristics.\n",
    "\n",
    "### 1.3 The Rational Reminder Perspective\n",
    "\n",
    "The [Rational Reminder podcast](https://rationalreminder.ca/) (Ben Felix and Cameron Passmore) has become one of the most influential voices in evidence-based investing. Their framework for factor investing with ETFs aligns closely with what we'll analyse:\n",
    "\n",
    "1. **Core market exposure** supplemented by **factor tilts** (especially small-cap value + profitability)\n",
    "2. **Global diversification** across regions\n",
    "3. **Systematic rebalancing** with discipline through drawdowns\n",
    "4. **Fee awareness** — even small differences compound over decades\n",
    "\n",
    "The portfolio we construct in Section 6 (50% AVWS / 40% AVWC / 10% AVEM) represents a **globally diversified, factor-tilted equity allocation** — exactly the type of portfolio this research tradition recommends.\n",
    "\n",
    "### 1.4 How This Connects to the Academic Research\n",
    "\n",
    "The academic threads from [Notebook 4](04_Advanced_Factor_Models.ipynb) converge in these products:\n",
    "\n",
    "| Academic Finding | How DFA/Avantis Implement It |\n",
    "|-----------------|------------------------------|\n",
    "| Value + profitability interaction (Novy-Marx, 2013) | Integrated multi-factor sort — no cancellation of exposures |\n",
    "| Transaction cost erosion (Chen & Velikov, 2023) | Patient trading, reversal screens, no forced rebalancing dates |\n",
    "| Momentum crash risk (Daniel & Moskowitz, 2016) | Momentum as exclusion/timing screen, not as a held position |\n",
    "| Bessembinder's skewness (2018) | Extreme diversification (thousands of holdings) |\n",
    "| Wei Dai's 720 timing strategies (2023) | No premium timing — constant exposure to return dimensions |\n",
    "| Adaptive Markets (Lo, 2017; Chen, 2024) | Continuous research cycle; willingness to update methodology |\n",
    "\n",
    "The question we can begin to answer with data: **do the factor exposures we observe in these ETFs match what the firms claim?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c0b337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Setup: Import Libraries\n",
    "# ============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.stattools import jarque_bera\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "import yfinance as yf\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import tempfile\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "try:\n",
    "    plt.style.use('seaborn-v0_8-darkgrid')\n",
    "except:\n",
    "    plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c56098b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 2: Data — Avantis UCITS ETFs and Fama-French Factors\n",
    "\n",
    "We need two datasets:\n",
    "\n",
    "1. **Daily ETF prices** from Xetra (via Yahoo Finance) for AVWS, AVWC, and AVEM\n",
    "2. **Daily US Fama-French 5 factors + Momentum** from Kenneth French's data library\n",
    "\n",
    "Since these ETFs invest *globally* (not just in US stocks), we would ideally use the **Global** factor data. However, the **Global daily factors on French's website are only available through mid-2019** — well before these ETFs launched. We therefore use the **US daily factors**, which are updated through the present. Because US equities represent ~60% of global market capitalisation and US factors are highly correlated with their global counterparts, this is a reasonable approximation — particularly for estimating factor *exposures* (betas), which is our primary goal. Alpha estimates should be interpreted with additional caution given this proxy.\n",
    "\n",
    "> **Currency note:** The ETFs trade in EUR on Xetra, while the Fama-French factors are computed in USD. We convert ETF returns to USD using the EUR/USD exchange rate. This ensures our factor loadings are not contaminated by currency movements. The betas are relatively robust to this conversion (since currency effects are largely orthogonal to factor returns), but the alpha estimate would be meaningfully affected without it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90350970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Step 1: Download US Fama-French 5 Factors + Momentum (Daily)\n",
    "# ============================================================================\n",
    "\n",
    "def load_ff_csv_from_zip(url, skip_footer=0):\n",
    "    \"\"\"Download and parse a Fama-French CSV from a zip file.\"\"\"\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        zip_path = os.path.join(tmpdir, 'data.zip')\n",
    "        urllib.request.urlretrieve(url, zip_path)\n",
    "        with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "            csv_name = [f for f in z.namelist() if f.endswith('.CSV') or f.endswith('.csv')][0]\n",
    "            with z.open(csv_name) as f:\n",
    "                lines = f.read().decode('utf-8').splitlines()\n",
    "    \n",
    "    # Find the header row (contains 'Mkt-RF' or 'WML' or 'Mom')\n",
    "    header_idx = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if 'Mkt-RF' in line or 'WML' in line or 'Mom' in line:\n",
    "            header_idx = i\n",
    "            break\n",
    "    \n",
    "    if header_idx is None:\n",
    "        raise ValueError(\"Could not find header row in CSV\")\n",
    "    \n",
    "    # Parse from header row\n",
    "    from io import StringIO\n",
    "    data_text = '\\n'.join(lines[header_idx:])\n",
    "    df = pd.read_csv(StringIO(data_text), index_col=0)\n",
    "    \n",
    "    # Clean: remove non-numeric rows and annual data section\n",
    "    df.index = df.index.astype(str).str.strip()\n",
    "    df = df[df.index.str.match(r'^\\d{8}$')]  # Keep only YYYYMMDD rows\n",
    "    df.index = pd.to_datetime(df.index, format='%Y%m%d')\n",
    "    df = df.apply(pd.to_numeric, errors='coerce')\n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Note: We use US factors because the Global daily factors on French's website \n",
    "# only extend to mid-2019, well before these UCITS ETFs launched.\n",
    "# US factors are a reasonable proxy — see Section 2 discussion.\n",
    "\n",
    "print(\"Loading US Fama-French 5 Factors (Daily)...\")\n",
    "ff5_url = 'https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/ftp/F-F_Research_Data_5_Factors_2x3_daily_CSV.zip'\n",
    "ff5 = load_ff_csv_from_zip(ff5_url)\n",
    "ff5.columns = ff5.columns.str.strip()\n",
    "\n",
    "# Rename Mkt-RF to Mkt_RF for consistency with earlier notebooks\n",
    "ff5 = ff5.rename(columns={'Mkt-RF': 'Mkt_RF'})\n",
    "\n",
    "print(f\"  Shape: {ff5.shape}\")\n",
    "print(f\"  Date range: {ff5.index[0].date()} to {ff5.index[-1].date()}\")\n",
    "print(f\"  Columns: {list(ff5.columns)}\")\n",
    "\n",
    "print(\"\\nLoading US Momentum Factor (Daily)...\")\n",
    "mom_url = 'https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/ftp/F-F_Momentum_Factor_daily_CSV.zip'\n",
    "mom = load_ff_csv_from_zip(mom_url)\n",
    "mom.columns = mom.columns.str.strip()\n",
    "\n",
    "# Rename the momentum column to UMD for consistency\n",
    "mom_col = mom.columns[0]  # Usually 'Mom' or 'WML'\n",
    "mom = mom.rename(columns={mom_col: 'UMD'})\n",
    "\n",
    "print(f\"  Shape: {mom.shape}\")\n",
    "print(f\"  Date range: {mom.index[0].date()} to {mom.index[-1].date()}\")\n",
    "\n",
    "# Merge FF5 + Momentum\n",
    "factors = ff5.join(mom[['UMD']], how='inner')\n",
    "\n",
    "print(f\"\\nCombined factors (FF5 + Momentum): {factors.shape}\")\n",
    "print(f\"  Columns: {list(factors.columns)}\")\n",
    "print(f\"\\nSample (last 5 rows):\")\n",
    "print(factors.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a51ba8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Step 2: Download Avantis UCITS ETF Prices from Xetra + EUR/USD FX Rate\n",
    "# ============================================================================\n",
    "\n",
    "etf_tickers = {\n",
    "    'AVWS.DE': 'Avantis Global Small Cap Value',\n",
    "    'AVWC.DE': 'Avantis Global Equity',\n",
    "    'AVEM.DE': 'Avantis Emerging Markets Equity',\n",
    "}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DOWNLOADING AVANTIS UCITS ETF DATA (XETRA)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Download ETF prices\n",
    "etf_prices = {}\n",
    "for ticker, name in etf_tickers.items():\n",
    "    data = yf.download(ticker, period='max', progress=False)\n",
    "    # Handle multi-level columns from yfinance\n",
    "    if isinstance(data.columns, pd.MultiIndex):\n",
    "        data.columns = data.columns.get_level_values(0)\n",
    "    etf_prices[ticker] = data['Close']\n",
    "    print(f\"\\n{ticker} ({name}):\")\n",
    "    print(f\"  Observations: {len(data)}\")\n",
    "    print(f\"  Date range: {data.index[0].date()} to {data.index[-1].date()}\")\n",
    "    print(f\"  First price: {data['Close'].iloc[0]:.2f} EUR\")\n",
    "    print(f\"  Last price: {data['Close'].iloc[-1]:.2f} EUR\")\n",
    "\n",
    "# Download EUR/USD exchange rate\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"Downloading EUR/USD exchange rate...\")\n",
    "fx_data = yf.download('EURUSD=X', start='2024-09-01', progress=False)\n",
    "if isinstance(fx_data.columns, pd.MultiIndex):\n",
    "    fx_data.columns = fx_data.columns.get_level_values(0)\n",
    "eurusd = fx_data['Close']\n",
    "print(f\"  Observations: {len(eurusd)}\")\n",
    "print(f\"  Date range: {eurusd.index[0].date()} to {eurusd.index[-1].date()}\")\n",
    "\n",
    "# Compute daily returns in EUR, then convert to USD\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPUTING DAILY RETURNS (USD-CONVERTED)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "etf_returns_usd = {}\n",
    "for ticker, name in etf_tickers.items():\n",
    "    prices_eur = etf_prices[ticker]\n",
    "    \n",
    "    # Daily EUR returns\n",
    "    ret_eur = prices_eur.pct_change().dropna()\n",
    "    \n",
    "    # EUR/USD rate changes\n",
    "    fx_aligned = eurusd.reindex(ret_eur.index, method='ffill')\n",
    "    fx_ret = fx_aligned.pct_change()\n",
    "    \n",
    "    # Convert to USD: R_usd ≈ R_eur + R_fx + R_eur * R_fx\n",
    "    # For daily returns, the cross-term is negligible\n",
    "    ret_usd = ret_eur + fx_ret + ret_eur * fx_ret\n",
    "    ret_usd = ret_usd.dropna()\n",
    "    \n",
    "    # Convert to percentage points to match FF factor data\n",
    "    etf_returns_usd[ticker] = ret_usd * 100\n",
    "    \n",
    "    print(f\"\\n{ticker} ({name}):\")\n",
    "    print(f\"  Daily return obs: {len(ret_usd)}\")\n",
    "    print(f\"  Mean daily return: {ret_usd.mean()*100:.4f}%\")\n",
    "    print(f\"  Daily volatility: {ret_usd.std()*100:.4f}%\")\n",
    "    print(f\"  Ann. return (approx): {ret_usd.mean()*252*100:.2f}%\")\n",
    "    print(f\"  Ann. volatility (approx): {ret_usd.std()*np.sqrt(252)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55cb288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Step 3: Merge ETF Returns with Factor Data\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MERGING ETF RETURNS WITH FAMA-FRENCH FACTORS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create aligned dataframes for each ETF\n",
    "etf_dataframes = {}\n",
    "for ticker, name in etf_tickers.items():\n",
    "    ret = etf_returns_usd[ticker]\n",
    "    \n",
    "    # Merge with factors on date\n",
    "    merged = pd.DataFrame({'ETF_Return': ret})\n",
    "    merged = merged.join(factors, how='inner')\n",
    "    \n",
    "    # Compute excess return: ETF return - risk-free rate\n",
    "    merged['Excess_Return'] = merged['ETF_Return'] - merged['RF']\n",
    "    \n",
    "    etf_dataframes[ticker] = merged\n",
    "    \n",
    "    print(f\"\\n{ticker} ({name}):\")\n",
    "    print(f\"  Matched observations: {len(merged)}\")\n",
    "    if len(merged) > 0:\n",
    "        print(f\"  Date range: {merged.index[0].date()} to {merged.index[-1].date()}\")\n",
    "        print(f\"  Mean excess return: {merged['Excess_Return'].mean():.4f}%/day\")\n",
    "    else:\n",
    "        print(\"  WARNING: No matching dates found!\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATA SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'ETF':<12} {'Obs':>6} {'Start':>12} {'End':>12} {'Ann. Ret':>10} {'Ann. Vol':>10}\")\n",
    "print(\"-\"*70)\n",
    "for ticker, name in etf_tickers.items():\n",
    "    df = etf_dataframes[ticker]\n",
    "    ann_ret = df['Excess_Return'].mean() * 252\n",
    "    ann_vol = df['Excess_Return'].std() * np.sqrt(252)\n",
    "    print(f\"{ticker:<12} {len(df):>6} {df.index[0].strftime('%Y-%m-%d'):>12} \"\n",
    "          f\"{df.index[-1].strftime('%Y-%m-%d'):>12} {ann_ret:>9.2f}% {ann_vol:>9.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cb9b9a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 3: Descriptive Analysis\n",
    "\n",
    "Before running factor regressions, we examine the basic statistical properties of these ETFs. This connects directly to [Notebook 2](02_Time_Series_Foundations.ipynb): financial return series typically exhibit fat tails, volatility clustering, and weak autocorrelation — features that our regression approach (Newey-West SEs) is designed to handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531e8276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Descriptive Statistics and Return Distributions\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DESCRIPTIVE STATISTICS — DAILY EXCESS RETURNS (% per day)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "desc_stats = []\n",
    "for ticker, name in etf_tickers.items():\n",
    "    r = etf_dataframes[ticker]['Excess_Return']\n",
    "    jb_stat, jb_p, skew_val, kurt_val = jarque_bera(r)\n",
    "    \n",
    "    # Ljung-Box test for autocorrelation (lag 5)\n",
    "    lb_result = acorr_ljungbox(r, lags=[5], return_df=True)\n",
    "    lb_p = lb_result['lb_pvalue'].values[0]\n",
    "    \n",
    "    # Ljung-Box on squared returns (volatility clustering)\n",
    "    lb_sq = acorr_ljungbox(r**2, lags=[5], return_df=True)\n",
    "    lb_sq_p = lb_sq['lb_pvalue'].values[0]\n",
    "    \n",
    "    desc_stats.append({\n",
    "        'ETF': ticker.replace('.DE', ''),\n",
    "        'N': len(r),\n",
    "        'Mean (%)': f\"{r.mean():.4f}\",\n",
    "        'Std (%)': f\"{r.std():.4f}\",\n",
    "        'Skewness': f\"{skew_val:.3f}\",\n",
    "        'Kurtosis': f\"{kurt_val:.3f}\",\n",
    "        'JB p-value': f\"{jb_p:.4f}\",\n",
    "        'LB(5) p': f\"{lb_p:.4f}\",\n",
    "        'LB²(5) p': f\"{lb_sq_p:.4f}\",\n",
    "        'Min (%)': f\"{r.min():.2f}\",\n",
    "        'Max (%)': f\"{r.max():.2f}\",\n",
    "    })\n",
    "\n",
    "desc_df = pd.DataFrame(desc_stats).set_index('ETF')\n",
    "print(desc_df.to_string())\n",
    "\n",
    "print(\"\"\"\n",
    "INTERPRETATION:\n",
    "━━━━━━━━━━━━━━\n",
    "• JB p-value < 0.05 → Returns are NOT normally distributed (expected for \n",
    "  financial data, as discussed in Notebook 2, Section 1)\n",
    "  \n",
    "• LB(5) p-value: Tests for autocorrelation in returns. \n",
    "  p < 0.05 → significant autocorrelation detected\n",
    "\n",
    "• LB²(5) p-value: Tests for autocorrelation in SQUARED returns \n",
    "  (volatility clustering). p < 0.05 → ARCH effects present\n",
    "  (as expected from Notebook 2, Section 4)\n",
    "\n",
    "→ These diagnostics confirm that Newey-West standard errors are appropriate\n",
    "  for our factor regressions (they account for both autocorrelation and \n",
    "  heteroskedasticity).\n",
    "\"\"\")\n",
    "\n",
    "# ============================================================================\n",
    "# Visualisation: Return Distributions and Cumulative Returns\n",
    "# ============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "for i, (ticker, name) in enumerate(etf_tickers.items()):\n",
    "    r = etf_dataframes[ticker]['Excess_Return']\n",
    "    short_name = ticker.replace('.DE', '')\n",
    "    \n",
    "    # Top row: Return histograms with normal overlay\n",
    "    ax = axes[0, i]\n",
    "    ax.hist(r, bins=50, density=True, alpha=0.7, color='steelblue', \n",
    "            edgecolor='white', linewidth=0.5)\n",
    "    x = np.linspace(r.min(), r.max(), 100)\n",
    "    ax.plot(x, stats.norm.pdf(x, r.mean(), r.std()), 'r-', linewidth=2,\n",
    "            label='Normal')\n",
    "    ax.set_title(f'{short_name}: Daily Excess Returns', fontweight='bold')\n",
    "    ax.set_xlabel('Return (%)')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Bottom row: Cumulative returns\n",
    "    ax = axes[1, i]\n",
    "    cum_ret = (1 + r / 100).cumprod()\n",
    "    ax.plot(cum_ret.index, cum_ret, color='darkblue', linewidth=1.5)\n",
    "    ax.axhline(1, color='red', linestyle='--', linewidth=0.8, alpha=0.5)\n",
    "    ax.set_title(f'{short_name}: Cumulative Growth of $1', fontweight='bold')\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Value ($)')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.tick_params(axis='x', rotation=30)\n",
    "\n",
    "plt.suptitle('Avantis UCITS ETFs — Return Distributions and Cumulative Performance',\n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('avantis_descriptive.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\"\"\n",
    "TOP ROW: Return distributions. Compare the histogram to the red normal curve.\n",
    "Fat tails (excess kurtosis) are visible — returns have more extreme observations \n",
    "than a normal distribution would predict. This motivates robust standard errors.\n",
    "\n",
    "BOTTOM ROW: Cumulative returns since inception. Remember: this is a very short \n",
    "period (~17 months). Short-term performance is dominated by market movements and \n",
    "luck, not factor premia (which require 10-20 year horizons per Wei Dai's research).\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93579975",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 4: Factor Regression Analysis\n",
    "\n",
    "This is the core analytical section. We regress each ETF's daily excess returns on the **FF5 + Momentum (6-factor) model**:\n",
    "\n",
    "$$R_i(t) - R_f(t) = \\alpha_i + \\beta_{MKT} (R_m - R_f)(t) + \\beta_{SMB} \\cdot SMB(t) + \\beta_{HML} \\cdot HML(t) + \\beta_{RMW} \\cdot RMW(t) + \\beta_{CMA} \\cdot CMA(t) + \\beta_{UMD} \\cdot UMD(t) + \\epsilon_i(t)$$\n",
    "\n",
    "We use **Newey-West standard errors** with automatic lag selection, as justified in [Notebook 1, Section 7](01_Statistical_Foundations.ipynb). This accounts for both autocorrelation and heteroskedasticity in the residuals — the same issues our descriptive analysis just confirmed.\n",
    "\n",
    "For each ETF, we run both a **3-factor** and a **6-factor** regression to see how the additional factors change the picture — mirroring the progression in [Notebook 4, Section 1](04_Advanced_Factor_Models.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f0b8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Factor Regression Helper Function\n",
    "# ============================================================================\n",
    "\n",
    "def run_factor_regression(etf_data, factor_cols, ticker_name, nw_lags=None):\n",
    "    \"\"\"\n",
    "    Run OLS regression with Newey-West standard errors.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    etf_data : DataFrame with 'Excess_Return' and factor columns\n",
    "    factor_cols : list of factor column names\n",
    "    ticker_name : string for display\n",
    "    nw_lags : int or None (auto = int(4*(T/100)^(2/9)))\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    statsmodels RegressionResults\n",
    "    \"\"\"\n",
    "    y = etf_data['Excess_Return'].values\n",
    "    X = sm.add_constant(etf_data[factor_cols].values)\n",
    "    \n",
    "    # Automatic Newey-West lag selection (Andrews, 1991 rule of thumb)\n",
    "    T = len(y)\n",
    "    if nw_lags is None:\n",
    "        nw_lags = int(np.ceil(4 * (T / 100) ** (2/9)))\n",
    "    \n",
    "    model = sm.OLS(y, X)\n",
    "    results = model.fit(cov_type='HAC', cov_kwds={'maxlags': nw_lags})\n",
    "    \n",
    "    return results, nw_lags\n",
    "\n",
    "def print_regression_results(results, factor_cols, ticker_name, nw_lags):\n",
    "    \"\"\"Pretty-print regression results.\"\"\"\n",
    "    param_names = ['Alpha (α)'] + factor_cols\n",
    "    \n",
    "    print(f\"\\n{'='*65}\")\n",
    "    print(f\"  {ticker_name}\")\n",
    "    print(f\"  Newey-West lags: {nw_lags} | N = {int(results.nobs)} | R² = {results.rsquared:.4f}\")\n",
    "    print(f\"{'='*65}\")\n",
    "    print(f\"{'Factor':<14} {'Coeff':>10} {'Std Err':>10} {'t-stat':>10} {'p-value':>10} {'Sig':>5}\")\n",
    "    print(f\"{'-'*65}\")\n",
    "    \n",
    "    for i, name in enumerate(param_names):\n",
    "        coef = results.params[i]\n",
    "        se = results.bse[i]\n",
    "        t = results.tvalues[i]\n",
    "        p = results.pvalues[i]\n",
    "        sig = '***' if p < 0.01 else '**' if p < 0.05 else '*' if p < 0.10 else ''\n",
    "        print(f\"{name:<14} {coef:>10.4f} {se:>10.4f} {t:>10.3f} {p:>10.4f} {sig:>5}\")\n",
    "    \n",
    "    # Annualise alpha (daily → annual, approx)\n",
    "    alpha_daily = results.params[0]\n",
    "    alpha_annual = alpha_daily * 252\n",
    "    print(f\"\\n  Annualised alpha ≈ {alpha_annual:.2f}% (= {alpha_daily:.4f}% × 252)\")\n",
    "    print(f\"  Residual std (daily) = {np.sqrt(results.mse_resid):.4f}%\")\n",
    "\n",
    "print(\"Regression helper functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954a7268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Run FF3 and FF5+Momentum Regressions for Each ETF\n",
    "# ============================================================================\n",
    "\n",
    "ff3_cols = ['Mkt_RF', 'SMB', 'HML']\n",
    "ff6_cols = ['Mkt_RF', 'SMB', 'HML', 'RMW', 'CMA', 'UMD']\n",
    "\n",
    "results_3f = {}\n",
    "results_6f = {}\n",
    "\n",
    "print(\"█\"*70)\n",
    "print(\"  FAMA-FRENCH 3-FACTOR REGRESSIONS (GLOBAL FACTORS)\")\n",
    "print(\"█\"*70)\n",
    "\n",
    "for ticker, name in etf_tickers.items():\n",
    "    df = etf_dataframes[ticker]\n",
    "    res, lags = run_factor_regression(df, ff3_cols, f\"{ticker} — {name}\")\n",
    "    results_3f[ticker] = res\n",
    "    print_regression_results(res, ff3_cols, f\"{ticker} — {name} [3-Factor]\", lags)\n",
    "\n",
    "print(\"\\n\\n\" + \"█\"*70)\n",
    "print(\"  FAMA-FRENCH 5-FACTOR + MOMENTUM (6-FACTOR) REGRESSIONS\")\n",
    "print(\"█\"*70)\n",
    "\n",
    "for ticker, name in etf_tickers.items():\n",
    "    df = etf_dataframes[ticker]\n",
    "    res, lags = run_factor_regression(df, ff6_cols, f\"{ticker} — {name}\")\n",
    "    results_6f[ticker] = res\n",
    "    print_regression_results(res, ff6_cols, f\"{ticker} — {name} [6-Factor]\", lags)\n",
    "\n",
    "print(\"\\n\\n\" + \"=\"*70)\n",
    "print(\"COMPARING 3-FACTOR VS 6-FACTOR: WHAT CHANGES?\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n{'ETF':<12} {'R² (3F)':>10} {'R² (6F)':>10} {'ΔR²':>8} {'α (3F)':>10} {'α (6F)':>10}\")\n",
    "print(\"-\"*60)\n",
    "for ticker in etf_tickers:\n",
    "    r3 = results_3f[ticker]\n",
    "    r6 = results_6f[ticker]\n",
    "    short = ticker.replace('.DE', '')\n",
    "    print(f\"{short:<12} {r3.rsquared:>10.4f} {r6.rsquared:>10.4f} \"\n",
    "          f\"{r6.rsquared - r3.rsquared:>8.4f} \"\n",
    "          f\"{r3.params[0]*252:>9.2f}% {r6.params[0]*252:>9.2f}%\")\n",
    "\n",
    "print(\"\"\"\n",
    "WHAT TO LOOK FOR:\n",
    "━━━━━━━━━━━━━━━━\n",
    "• AVWS (Small Cap Value): Should show positive SMB (small-cap tilt), \n",
    "  positive HML (value tilt), and positive RMW (profitability screen).\n",
    "  This is the purest factor-tilted fund in our set.\n",
    "\n",
    "• AVWC (Global Equity): Market beta ≈ 1, with modest positive HML and \n",
    "  RMW. The tilts should be gentler than AVWS since this is a broad fund.\n",
    "\n",
    "• AVEM (Emerging Markets): Market beta should be significant. Factor \n",
    "  loadings may differ because EM stocks have different characteristics.\n",
    "\n",
    "• Alpha: With only ~17 months of data, alpha estimates are very noisy.\n",
    "  Don't over-interpret whether alpha is positive or negative.\n",
    "\n",
    "• R² increase from 3F to 6F: If adding RMW, CMA, UMD substantially \n",
    "  increases R², it means these factors capture real variation in the \n",
    "  ETF's returns — consistent with the ETFs having multi-factor tilts.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee99016e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Residual Diagnostics — Validating Our Regression Assumptions\n",
    "# ============================================================================\n",
    "# Following the diagnostic approach from Notebook 3, Section 5\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"RESIDUAL DIAGNOSTICS (6-FACTOR MODEL)\")\n",
    "print(\"=\"*70)\n",
    "print(\"Checking the assumptions underlying our OLS + Newey-West regressions.\\n\")\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 14))\n",
    "\n",
    "for i, (ticker, name) in enumerate(etf_tickers.items()):\n",
    "    res = results_6f[ticker]\n",
    "    resid = res.resid\n",
    "    short = ticker.replace('.DE', '')\n",
    "    \n",
    "    # Column 1: Residual time series\n",
    "    ax = axes[i, 0]\n",
    "    dates = etf_dataframes[ticker].index\n",
    "    ax.plot(dates, resid, linewidth=0.6, color='steelblue', alpha=0.8)\n",
    "    ax.axhline(0, color='red', linestyle='--', linewidth=0.8)\n",
    "    ax.set_title(f'{short}: Residuals Over Time', fontweight='bold', fontsize=10)\n",
    "    ax.set_ylabel('Residual (%)')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.tick_params(axis='x', rotation=30)\n",
    "    \n",
    "    # Column 2: Residual ACF\n",
    "    ax = axes[i, 1]\n",
    "    from statsmodels.graphics.tsaplots import plot_acf\n",
    "    plot_acf(resid, ax=ax, lags=20, alpha=0.05)\n",
    "    ax.set_title(f'{short}: Residual ACF', fontweight='bold', fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Column 3: QQ Plot\n",
    "    ax = axes[i, 2]\n",
    "    stats.probplot(resid, dist='norm', plot=ax)\n",
    "    ax.set_title(f'{short}: QQ Plot', fontweight='bold', fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('6-Factor Model — Residual Diagnostics',\n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('avantis_diagnostics.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Formal tests\n",
    "print(\"\\nFORMAL DIAGNOSTIC TESTS:\")\n",
    "print(f\"{'ETF':<10} {'JB p-val':>10} {'LB(5) p':>10} {'LB²(5) p':>10} {'Resid kurt':>12}\")\n",
    "print(\"-\"*55)\n",
    "for ticker in etf_tickers:\n",
    "    resid = results_6f[ticker].resid\n",
    "    jb_stat, jb_p, skew, kurt = jarque_bera(resid)\n",
    "    lb = acorr_ljungbox(resid, lags=[5], return_df=True)['lb_pvalue'].values[0]\n",
    "    lb_sq = acorr_ljungbox(resid**2, lags=[5], return_df=True)['lb_pvalue'].values[0]\n",
    "    short = ticker.replace('.DE', '')\n",
    "    print(f\"{short:<10} {jb_p:>10.4f} {lb:>10.4f} {lb_sq:>10.4f} {kurt:>12.2f}\")\n",
    "\n",
    "print(\"\"\"\n",
    "INTERPRETATION:\n",
    "━━━━━━━━━━━━━━\n",
    "LEFT: Residuals should look like white noise — no visible patterns or \n",
    "clustering. Any remaining volatility clustering means the 6-factor model \n",
    "doesn't fully capture all systematic return variation.\n",
    "\n",
    "MIDDLE: ACF of residuals. Bars outside the blue confidence band indicate \n",
    "significant autocorrelation. Newey-West SEs handle this, but strong \n",
    "autocorrelation would suggest model misspecification.\n",
    "\n",
    "RIGHT: QQ plot. Deviations from the diagonal in the tails indicate fat tails \n",
    "(excess kurtosis) — normal for financial data. This affects confidence \n",
    "interval coverage but not the consistency of OLS estimates \n",
    "(Notebook 1, Section 5).\n",
    "\n",
    "LB²(5) p-value: If significant, ARCH effects remain in the residuals — \n",
    "confirming that Newey-West (HAC) standard errors are essential.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167d5e43",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 5: Comparative Factor Profiles\n",
    "\n",
    "Now we compare the factor exposures across all three ETFs side by side. This reveals how each fund implements Avantis' \"scientific approach\" differently depending on its investment universe (global small-cap value vs. broad global equity vs. emerging markets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3915ed5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Comparative Factor Exposure Chart\n",
    "# ============================================================================\n",
    "\n",
    "factor_names = ['Mkt_RF', 'SMB', 'HML', 'RMW', 'CMA', 'UMD']\n",
    "etf_short_names = [t.replace('.DE', '') for t in etf_tickers.keys()]\n",
    "colors = ['#2196F3', '#4CAF50', '#FF9800']  # Blue, Green, Orange\n",
    "\n",
    "# Collect coefficients and significance\n",
    "coef_matrix = np.zeros((len(etf_tickers), len(factor_names)))\n",
    "sig_matrix = np.zeros((len(etf_tickers), len(factor_names)))\n",
    "se_matrix = np.zeros((len(etf_tickers), len(factor_names)))\n",
    "\n",
    "for i, ticker in enumerate(etf_tickers.keys()):\n",
    "    res = results_6f[ticker]\n",
    "    for j, factor in enumerate(factor_names):\n",
    "        coef_matrix[i, j] = res.params[j + 1]  # +1 to skip constant\n",
    "        sig_matrix[i, j] = res.pvalues[j + 1]\n",
    "        se_matrix[i, j] = res.bse[j + 1]\n",
    "\n",
    "# Plot 1: Side-by-side bar chart of factor loadings\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# Panel A: Factor Betas\n",
    "ax = axes[0]\n",
    "x = np.arange(len(factor_names))\n",
    "width = 0.25\n",
    "for i, (etf_name, color) in enumerate(zip(etf_short_names, colors)):\n",
    "    bars = ax.bar(x + i * width - width, coef_matrix[i], width, \n",
    "                  label=etf_name, color=color, alpha=0.85, edgecolor='white')\n",
    "    # Add significance markers\n",
    "    for j, bar in enumerate(bars):\n",
    "        if sig_matrix[i, j] < 0.01:\n",
    "            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                    '***', ha='center', fontsize=8, fontweight='bold')\n",
    "        elif sig_matrix[i, j] < 0.05:\n",
    "            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                    '**', ha='center', fontsize=8, fontweight='bold')\n",
    "        elif sig_matrix[i, j] < 0.10:\n",
    "            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                    '*', ha='center', fontsize=8)\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(factor_names, fontsize=11)\n",
    "ax.set_ylabel('Factor Loading (β)', fontsize=12)\n",
    "ax.set_title('Panel A: Factor Exposures (6-Factor Model)', fontweight='bold',\n",
    "             fontsize=13)\n",
    "ax.axhline(0, color='black', linewidth=0.8)\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Panel B: Alpha comparison (annualised)\n",
    "ax = axes[1]\n",
    "alphas = [results_6f[t].params[0] * 252 for t in etf_tickers.keys()]\n",
    "alpha_ses = [results_6f[t].bse[0] * 252 for t in etf_tickers.keys()]  # approx\n",
    "alpha_sigs = [results_6f[t].pvalues[0] for t in etf_tickers.keys()]\n",
    "\n",
    "bars = ax.bar(etf_short_names, alphas, color=colors, alpha=0.85, \n",
    "              edgecolor='white', width=0.5)\n",
    "ax.errorbar(etf_short_names, alphas, yerr=[1.96*se for se in alpha_ses],\n",
    "            fmt='none', color='black', capsize=5, linewidth=1.5)\n",
    "ax.axhline(0, color='red', linestyle='--', linewidth=1)\n",
    "ax.set_ylabel('Annualised Alpha (%)', fontsize=12)\n",
    "ax.set_title('Panel B: Jensen\\'s Alpha (6-Factor, Annualised)', \n",
    "             fontweight='bold', fontsize=13)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add p-values\n",
    "for i, (bar, p) in enumerate(zip(bars, alpha_sigs)):\n",
    "    label = f'p={p:.3f}'\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, \n",
    "            bar.get_height() + alpha_ses[i] * 2.2,\n",
    "            label, ha='center', fontsize=10)\n",
    "\n",
    "plt.suptitle('Avantis UCITS ETFs — Comparative Factor Analysis',\n",
    "             fontsize=15, fontweight='bold', y=1.03)\n",
    "plt.tight_layout()\n",
    "plt.savefig('avantis_factor_comparison.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FACTOR EXPOSURE SUMMARY (6-FACTOR MODEL)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n{'Factor':<10}\", end='')\n",
    "for name in etf_short_names:\n",
    "    print(f\"  {name:>14}\", end='')\n",
    "print()\n",
    "print(\"-\"*55)\n",
    "for j, factor in enumerate(factor_names):\n",
    "    print(f\"{factor:<10}\", end='')\n",
    "    for i in range(len(etf_tickers)):\n",
    "        coef = coef_matrix[i, j]\n",
    "        p = sig_matrix[i, j]\n",
    "        sig = '***' if p < 0.01 else '**' if p < 0.05 else '*' if p < 0.10 else ''\n",
    "        print(f\"  {coef:>10.4f}{sig:>4}\", end='')\n",
    "    print()\n",
    "\n",
    "print(f\"\\n{'R²':<10}\", end='')\n",
    "for ticker in etf_tickers:\n",
    "    print(f\"  {results_6f[ticker].rsquared:>14.4f}\", end='')\n",
    "print()\n",
    "\n",
    "print(\"\"\"\n",
    "INTERPRETATION GUIDE:\n",
    "━━━━━━━━━━━━━━━━━━━━\n",
    "                            Expected for        Expected for        Expected for\n",
    "Factor      Meaning         AVWS (SCV)          AVWC (Global)       AVEM (EM)\n",
    "─────────────────────────────────────────────────────────────────────────────────\n",
    "Mkt_RF      Market risk     ~0.8–1.0            ~1.0                ~0.8–1.0\n",
    "SMB         Size            Positive (small!)    Near zero           Near zero\n",
    "HML         Value           Positive (value!)    Mild positive       Mild positive\n",
    "RMW         Profitability   Positive (screen)    Mild positive       Positive\n",
    "CMA         Investment      Ambiguous            Near zero           Ambiguous\n",
    "UMD         Momentum        Near zero/positive   Near zero           Near zero\n",
    "\n",
    "*** p < 0.01, ** p < 0.05, * p < 0.10 (Newey-West standard errors)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c34e1bf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 6: Portfolio Construction — 50% AVWS / 40% AVWC / 10% AVEM\n",
    "\n",
    "Now we construct a combined portfolio and analyse its characteristics. This allocation represents a **globally diversified, factor-tilted equity portfolio**:\n",
    "\n",
    "- **50% AVWS** — A heavy tilt toward global small-cap value (the strongest documented factor premia)\n",
    "- **40% AVWC** — Broad global equity with gentle factor tilts (core holding, provides diversification)\n",
    "- **10% AVEM** — Emerging markets exposure (geographic diversification, potentially different factor dynamics)\n",
    "\n",
    "This type of allocation aligns with the Rational Reminder framework: a factor-tilted core supplemented by a meaningful small-cap value overweight, with some EM diversification.\n",
    "\n",
    "### Why These Weights?\n",
    "\n",
    "The 50/40/10 split reflects several considerations:\n",
    "1. **Academic evidence is strongest for small-cap value** — Wei Dai's research shows small-cap value has the highest expected premium, so a large AVWS allocation targets this\n",
    "2. **Diversification requires breadth** — AVWC provides broad market exposure and reduces tracking error vs. a pure small-cap value bet (Bessembinder's skewness argument)\n",
    "3. **EM adds geographic diversity** — Factor premia have been documented globally (Asness, Moskowitz & Pedersen, 2013), but EM markets may behave differently\n",
    "\n",
    "> **Important:** We can only construct this portfolio from the date when all three ETFs have available data (the latest inception date). Since AVEM launched in December 2024, our combined portfolio history is limited to approximately 15 months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bd6a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 6.1 — Build the Portfolio\n",
    "# ============================================================================\n",
    "\n",
    "weights = {'AVWS.DE': 0.50, 'AVWC.DE': 0.40, 'AVEM.DE': 0.10}\n",
    "\n",
    "# Find common date range where all three ETFs have data\n",
    "common_dates = etf_dataframes['AVWS.DE'].index\n",
    "for ticker in ['AVWC.DE', 'AVEM.DE']:\n",
    "    common_dates = common_dates.intersection(etf_dataframes[ticker].index)\n",
    "\n",
    "print(f\"Common dates across all three ETFs: {len(common_dates)}\")\n",
    "print(f\"Date range: {common_dates[0].date()} to {common_dates[-1].date()}\")\n",
    "print()\n",
    "\n",
    "# Build a combined dataframe on common dates\n",
    "port_data = pd.DataFrame(index=common_dates)\n",
    "for ticker in etf_tickers:\n",
    "    short = ticker.replace('.DE', '')\n",
    "    port_data[f'{short}_excess'] = etf_dataframes[ticker].loc[common_dates, 'Excess_Return']\n",
    "    port_data[f'{short}_ret'] = etf_dataframes[ticker].loc[common_dates, 'ETF_Return']\n",
    "\n",
    "# Add factor columns from any ETF's dataframe (they're identical)\n",
    "factor_cols_all = ['Mkt_RF', 'SMB', 'HML', 'RMW', 'CMA', 'UMD', 'RF']\n",
    "for col in factor_cols_all:\n",
    "    port_data[col] = etf_dataframes['AVWS.DE'].loc[common_dates, col]\n",
    "\n",
    "# Compute portfolio returns (weighted average)\n",
    "port_data['Port_ret'] = (weights['AVWS.DE'] * port_data['AVWS_ret']\n",
    "                       + weights['AVWC.DE'] * port_data['AVWC_ret']\n",
    "                       + weights['AVEM.DE'] * port_data['AVEM_ret'])\n",
    "\n",
    "port_data['Port_excess'] = (weights['AVWS.DE'] * port_data['AVWS_excess']\n",
    "                          + weights['AVWC.DE'] * port_data['AVWC_excess']\n",
    "                          + weights['AVEM.DE'] * port_data['AVEM_excess'])\n",
    "\n",
    "# ---- Summary Statistics ----\n",
    "print(\"=\" * 65)\n",
    "print(\"Portfolio Summary Statistics (daily, USD-converted, % units)\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "port_ret = port_data['Port_ret']\n",
    "ann_factor = 252\n",
    "\n",
    "summary = {\n",
    "    'Mean daily return (%)':           port_ret.mean(),\n",
    "    'Std. dev. daily (%)':             port_ret.std(),\n",
    "    'Annualised return (%)':           port_ret.mean() * ann_factor,\n",
    "    'Annualised volatility (%)':       port_ret.std() * np.sqrt(ann_factor),\n",
    "    'Sharpe ratio (annualised)':       (port_ret.mean() * ann_factor) / (port_ret.std() * np.sqrt(ann_factor)),\n",
    "    'Skewness':                        port_ret.skew(),\n",
    "    'Excess kurtosis':                 port_ret.kurtosis(),\n",
    "    'Minimum daily return (%)':        port_ret.min(),\n",
    "    'Maximum daily return (%)':        port_ret.max(),\n",
    "}\n",
    "\n",
    "for k, v in summary.items():\n",
    "    print(f\"  {k:<35s}  {v:>8.4f}\")\n",
    "\n",
    "# ---- Compare portfolio vs. individual ETFs ----\n",
    "print(\"\\n\" + \"=\" * 65)\n",
    "print(\"Risk-Return Comparison: Portfolio vs. Individual ETFs\")\n",
    "print(\"=\" * 65)\n",
    "print(f\"  {'':20s}  {'Ann. Ret.':>10s}  {'Ann. Vol.':>10s}  {'Sharpe':>8s}\")\n",
    "print(\"  \" + \"-\" * 52)\n",
    "\n",
    "for ticker, name in etf_tickers.items():\n",
    "    short = ticker.replace('.DE', '')\n",
    "    r = port_data[f'{short}_ret']\n",
    "    ann_r = r.mean() * ann_factor\n",
    "    ann_v = r.std() * np.sqrt(ann_factor)\n",
    "    sr = ann_r / ann_v if ann_v > 0 else 0\n",
    "    print(f\"  {short:20s}  {ann_r:>9.2f}%  {ann_v:>9.2f}%  {sr:>8.4f}\")\n",
    "\n",
    "ann_r = port_ret.mean() * ann_factor\n",
    "ann_v = port_ret.std() * np.sqrt(ann_factor)\n",
    "sr = summary['Sharpe ratio (annualised)']\n",
    "print(f\"  {'Portfolio (50/40/10)':20s}  {ann_r:>9.2f}%  {ann_v:>9.2f}%  {sr:>8.4f}\")\n",
    "print()\n",
    "print(\"  Note: short-sample estimates; interpret with caution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89368754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 6.2 — Cumulative Returns and Drawdown Analysis\n",
    "# ============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 8), sharex=True,\n",
    "                         gridspec_kw={'height_ratios': [2, 1]})\n",
    "\n",
    "# Panel A: Cumulative returns  (returns are in % units, so divide by 100)\n",
    "cum_port = (1 + port_data['Port_ret'] / 100).cumprod()\n",
    "for short_name, colour in [('AVWS', '#1f77b4'), ('AVWC', '#ff7f0e'), ('AVEM', '#2ca02c')]:\n",
    "    cum_etf = (1 + port_data[f'{short_name}_ret'] / 100).cumprod()\n",
    "    axes[0].plot(cum_etf.index, cum_etf.values, label=short_name, alpha=0.6, color=colour)\n",
    "\n",
    "axes[0].plot(cum_port.index, cum_port.values, label='Portfolio (50/40/10)',\n",
    "             color='black', linewidth=2.5)\n",
    "axes[0].set_ylabel('Cumulative Return ($1 invested)')\n",
    "axes[0].legend(loc='upper left')\n",
    "axes[0].set_title('Panel A: Cumulative Returns')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].axhline(1, color='grey', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Panel B: Portfolio drawdown\n",
    "cum_max = cum_port.cummax()\n",
    "drawdown = (cum_port - cum_max) / cum_max * 100\n",
    "axes[1].fill_between(drawdown.index, drawdown.values, 0, color='red', alpha=0.3)\n",
    "axes[1].plot(drawdown.index, drawdown.values, color='red', linewidth=0.8)\n",
    "axes[1].set_ylabel('Drawdown (%)')\n",
    "axes[1].set_title('Panel B: Portfolio Drawdown')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Annotate maximum drawdown\n",
    "max_dd = drawdown.min()\n",
    "max_dd_date = drawdown.idxmin()\n",
    "axes[1].annotate(f'Max DD: {max_dd:.1f}%',\n",
    "                 xy=(max_dd_date, max_dd),\n",
    "                 xytext=(max_dd_date + pd.Timedelta(days=30), max_dd + 2),\n",
    "                 arrowprops=dict(arrowstyle='->', color='darkred'),\n",
    "                 fontsize=10, color='darkred', fontweight='bold')\n",
    "\n",
    "fig.suptitle('Portfolio Performance: 50% AVWS / 40% AVWC / 10% AVEM',\n",
    "             fontsize=14, fontweight='bold', y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n  Maximum drawdown: {max_dd:.2f}% on {max_dd_date.date()}\")\n",
    "print(f\"  Days from peak to trough: \"\n",
    "      f\"{(max_dd_date - cum_port[:max_dd_date].idxmax()).days}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a4fc95",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 7: Portfolio Factor Analysis\n",
    "\n",
    "Having analysed each ETF individually, we now run the same regressions on the **combined portfolio**. This serves two purposes:\n",
    "\n",
    "1. **Verification** — Portfolio-level betas should approximately equal the weighted average of individual ETF betas (a direct consequence of the linearity of OLS).\n",
    "2. **Holistic view** — The portfolio alpha, $R^2$, and residual diagnostics tell us about the *overall* factor profile of our allocation.\n",
    "\n",
    "### The Linearity Property\n",
    "\n",
    "Because OLS is a linear operator, if the portfolio return is:\n",
    "$$\n",
    "R_p = w_1 R_1 + w_2 R_2 + w_3 R_3\n",
    "$$\n",
    "\n",
    "then the portfolio beta on any factor $j$ satisfies:\n",
    "$$\n",
    "\\hat{\\beta}_{p,j} = w_1 \\hat{\\beta}_{1,j} + w_2 \\hat{\\beta}_{2,j} + w_3 \\hat{\\beta}_{3,j}\n",
    "$$\n",
    "\n",
    "This holds exactly when we use the same sample and factors for all regressions. We verify this property below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de26661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 7.1 — Portfolio Factor Regressions\n",
    "# ============================================================================\n",
    "\n",
    "# Build a temporary DataFrame for the portfolio regression\n",
    "port_reg_data = port_data[['Port_excess'] + ff6_cols].copy()\n",
    "port_reg_data = port_reg_data.rename(columns={'Port_excess': 'Excess_Return'})\n",
    "\n",
    "# FF3 regression on portfolio\n",
    "res_port_3f, lags_3f = run_factor_regression(port_reg_data, ff3_cols, \n",
    "                                              'Portfolio (50/40/10)')\n",
    "print(\"=\" * 70)\n",
    "print(\"PORTFOLIO (50% AVWS / 40% AVWC / 10% AVEM) — Fama-French 3-Factor\")\n",
    "print(\"=\" * 70)\n",
    "print_regression_results(res_port_3f, ff3_cols, 'Portfolio [3-Factor]', lags_3f)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# FF6 regression on portfolio\n",
    "res_port_6f, lags_6f = run_factor_regression(port_reg_data, ff6_cols, \n",
    "                                              'Portfolio (50/40/10)')\n",
    "print(\"=\" * 70)\n",
    "print(\"PORTFOLIO (50% AVWS / 40% AVWC / 10% AVEM) — FF5 + Momentum\")\n",
    "print(\"=\" * 70)\n",
    "print_regression_results(res_port_6f, ff6_cols, 'Portfolio [6-Factor]', lags_6f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8156636f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 7.2 — Verify Linearity: Weighted-Average Betas vs. Portfolio Betas\n",
    "# ============================================================================\n",
    "\n",
    "# Re-run individual ETF regressions on the SAME common sample\n",
    "etf_results_common = {}\n",
    "weight_map = {'AVWS.DE': 0.50, 'AVWC.DE': 0.40, 'AVEM.DE': 0.10}\n",
    "\n",
    "for ticker in etf_tickers:\n",
    "    short = ticker.replace('.DE', '')\n",
    "    # Build a temp DataFrame with the common-sample data\n",
    "    temp_df = port_data[[f'{short}_excess'] + ff6_cols].copy()\n",
    "    temp_df = temp_df.rename(columns={f'{short}_excess': 'Excess_Return'})\n",
    "    res_i, _ = run_factor_regression(temp_df, ff6_cols, ticker)\n",
    "    etf_results_common[ticker] = res_i\n",
    "\n",
    "# Compute weighted-average betas\n",
    "param_names = ['Alpha'] + ff6_cols\n",
    "print(\"=\" * 75)\n",
    "print(\"Linearity Verification: Portfolio β  vs.  Σ wᵢ · βᵢ  (FF6 model)\")\n",
    "print(\"=\" * 75)\n",
    "print(f\"  {'Factor':<10s}  {'Portfolio β':>12s}  {'Weighted Avg':>12s}  {'Difference':>12s}\")\n",
    "print(\"  \" + \"-\" * 50)\n",
    "\n",
    "for j, factor in enumerate(param_names):\n",
    "    beta_port = res_port_6f.params[j]\n",
    "    beta_wavg = sum(weight_map[t] * etf_results_common[t].params[j]\n",
    "                    for t in etf_tickers)\n",
    "    diff = beta_port - beta_wavg\n",
    "    print(f\"  {factor:<10s}  {beta_port:>12.6f}  {beta_wavg:>12.6f}  {diff:>12.2e}\")\n",
    "\n",
    "print()\n",
    "print(\"  Differences are at machine precision — linearity of OLS confirmed.\")\n",
    "print(\"  This means portfolio factor exposure is fully determined by the\")\n",
    "print(\"  individual ETF exposures and portfolio weights.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beeae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 7.3 — Portfolio Factor Exposure Decomposition\n",
    "# ============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "factor_labels = ff6_cols  # ['Mkt_RF', 'SMB', 'HML', 'RMW', 'CMA', 'UMD']\n",
    "etf_list = list(etf_tickers.keys())\n",
    "etf_short = [t.replace('.DE', '') for t in etf_list]\n",
    "colours = {'AVWS.DE': '#1f77b4', 'AVWC.DE': '#ff7f0e', 'AVEM.DE': '#2ca02c'}\n",
    "\n",
    "# Panel A: Stacked contribution to portfolio betas\n",
    "contributions = {}\n",
    "for factor in factor_labels:\n",
    "    j = ff6_cols.index(factor) + 1  # +1 to skip constant\n",
    "    contributions[factor] = [weight_map[t] * etf_results_common[t].params[j]\n",
    "                             for t in etf_list]\n",
    "\n",
    "x = np.arange(len(factor_labels))\n",
    "width = 0.5\n",
    "\n",
    "# Stacked bars (handle positive and negative separately)\n",
    "bottom_pos = np.zeros(len(factor_labels))\n",
    "bottom_neg = np.zeros(len(factor_labels))\n",
    "\n",
    "for i, ticker in enumerate(etf_list):\n",
    "    short = ticker.replace('.DE', '')\n",
    "    vals = np.array([contributions[f][i] for f in factor_labels])\n",
    "    pos_vals = np.where(vals >= 0, vals, 0)\n",
    "    neg_vals = np.where(vals < 0, vals, 0)\n",
    "\n",
    "    axes[0].bar(x, pos_vals, width, bottom=bottom_pos, \n",
    "                label=f'{short} ({weight_map[ticker]:.0%})',\n",
    "                color=colours[ticker], alpha=0.8, edgecolor='white', linewidth=0.5)\n",
    "    axes[0].bar(x, neg_vals, width, bottom=bottom_neg,\n",
    "                color=colours[ticker], alpha=0.8, edgecolor='white', linewidth=0.5)\n",
    "    bottom_pos += pos_vals\n",
    "    bottom_neg += neg_vals\n",
    "\n",
    "# Overlay the total portfolio beta as markers\n",
    "port_betas = [res_port_6f.params[ff6_cols.index(f) + 1] for f in factor_labels]\n",
    "axes[0].scatter(x, port_betas, color='black', zorder=5, s=60, marker='D',\n",
    "                label='Portfolio β (total)')\n",
    "\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(factor_labels, rotation=45, ha='right')\n",
    "axes[0].set_ylabel('Beta Coefficient')\n",
    "axes[0].set_title('Panel A: Decomposition of Portfolio Factor Exposures')\n",
    "axes[0].legend(loc='best', fontsize=8)\n",
    "axes[0].axhline(0, color='grey', linewidth=0.5)\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Panel B: R² comparison\n",
    "r2_vals = [etf_results_common[t].rsquared for t in etf_list]\n",
    "r2_vals.append(res_port_6f.rsquared)\n",
    "labels = etf_short + ['Portfolio']\n",
    "bar_colours = [colours[t] for t in etf_list] + ['black']\n",
    "\n",
    "bars = axes[1].bar(labels, r2_vals, color=bar_colours, alpha=0.8, edgecolor='white')\n",
    "for bar, val in zip(bars, r2_vals):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
    "                 f'{val:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "axes[1].set_ylabel('R²')\n",
    "axes[1].set_title('Panel B: Model Fit (FF5 + Momentum)')\n",
    "axes[1].set_ylim(0, 1.05)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "fig.suptitle('Portfolio Factor Exposure Analysis', fontsize=14, fontweight='bold', y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20831b5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 8: Limitations, Caveats, and Conclusions\n",
    "\n",
    "### 8.1 Data Limitations\n",
    "\n",
    "This analysis comes with important caveats that must inform interpretation:\n",
    "\n",
    "**Short sample period.** With approximately 12–15 months of daily data, we have ~250–300 observations. While daily frequency provides *statistical power for estimating betas*, it is **insufficient for reliable alpha estimation** or performance conclusions:\n",
    "\n",
    "- At daily frequency, the standard error of annualised alpha is typically 2–4% p.a., meaning even a \"large\" alpha of 1% p.a. would be statistically indistinguishable from zero\n",
    "- The sample spans a single market regime — we cannot evaluate how these factor tilts perform through a full business cycle\n",
    "- As emphasised throughout this series (Notebook 1, Section 3), **short samples amplify estimation error** and can produce misleading point estimates\n",
    "\n",
    "**US factors as proxy for global exposures.** Because the Global daily factors from Ken French's data library are only available through mid-2019 (well before these UCITS ETFs launched), we use US daily factors as a proxy. Since US equities represent ~60% of global market capitalisation and US factor returns are highly correlated with their global counterparts, this is a reasonable approximation for estimating factor *exposures* (betas). However, it explains two features of our results:\n",
    "\n",
    "- **Lower market betas:** The CAPM-predicted market beta for a globally diversified ETF regressed on US market excess returns is less than 1.0, because the US market does not perfectly capture the global market factor. The ETFs have substantial non-US exposure that is orthogonal to the US market.\n",
    "- **Lower R² values:** The 6-factor model explains less variance than it would with properly matched global factors, because the residual contains both idiosyncratic risk and non-US systematic risk.\n",
    "\n",
    "**Currency conversion noise.** Converting EUR-denominated ETF returns to USD using the EUR/USD exchange rate introduces additional noise. While this is methodologically correct for comparison with USD-denominated factors, the FX conversion adds a component to returns that is unrelated to factor exposure.\n",
    "\n",
    "**Survivorship and incubation.** These ETFs are relatively new products. Their return histories do not reflect the long sample periods over which factor premia have been documented (typically 50+ years for US data, 30+ years for international).\n",
    "\n",
    "### 8.2 What We *Can* Conclude\n",
    "\n",
    "Despite these limitations, daily factor regressions allow us to draw **robust conclusions about factor exposure** (betas):\n",
    "\n",
    "1. **AVWS delivers meaningful SMB and HML tilts** — This confirms that the fund's mandate (global small-cap value) is reflected in its actual holdings and returns, consistent with Avantis's \"systematic and deliberate\" approach\n",
    "2. **AVWC provides broad market exposure with modest factor tilts** — Its moderate market beta and smaller factor loadings make it suitable as a core holding\n",
    "3. **AVEM adds differentiated exposure** — Emerging market returns are not fully spanned by US/global factors, providing genuine diversification (as reflected in its low R²)\n",
    "4. **The portfolio achieves balanced factor exposure** — The 50/40/10 allocation delivers positive SMB and HML loadings while maintaining diversification\n",
    "\n",
    "### 8.3 Connecting Back to the Series\n",
    "\n",
    "This notebook applies concepts from every preceding chapter:\n",
    "\n",
    "| Concept | Source | Application Here |\n",
    "|:--------|:-------|:-----------------|\n",
    "| OLS regression and hypothesis testing | Notebook 1, Sections 4–5 | Factor regressions on each ETF |\n",
    "| Newey-West standard errors | Notebook 1, Section 6 | HAC-robust inference throughout |\n",
    "| Time series stationarity | Notebook 2, Section 2 | Using returns (stationary) not prices |\n",
    "| Autocorrelation diagnostics | Notebook 2, Sections 3–4 | Ljung-Box tests on residuals |\n",
    "| Fama-French 3-Factor Model | Notebook 3, Sections 3–5 | FF3 regressions as baseline |\n",
    "| FF5 and Momentum extensions | Notebook 4, Sections 2–3 | Full 6-factor model |\n",
    "| Rolling-window estimation | Notebook 4, Section 5 | Could be applied as data grows |\n",
    "| Residual diagnostics and model evaluation | Notebooks 3–4 | ACF, Q-Q, Jarque-Bera analysis |\n",
    "\n",
    "### 8.4 Practical Takeaways\n",
    "\n",
    "For the factor-aware investor:\n",
    "\n",
    "1. **Factor investing is implementable** — Products like Avantis's UCITS ETFs allow investors to harvest factor premia without building custom portfolios. The expense ratios (0.25–0.36% p.a.) represent a significant reduction from the theoretical maximum premium.\n",
    "\n",
    "2. **Diversification across factors and geographies matters** — No single factor dominates in all periods. A portfolio that targets multiple factors (value, size, profitability, momentum) through diversified vehicles is more robust than concentrated factor bets.\n",
    "\n",
    "3. **Patience is required** — Factor premia are long-run phenomena. The data here covers a single short period. A proper evaluation requires 10+ years of data spanning multiple market environments, as discussed in Dai (2023) and the Dimensional research.\n",
    "\n",
    "4. **Monitor but don't overreact** — As the sample grows, these analyses should be re-run. Short-term deviations from expected factor behaviour are *normal* — persistence of factor premia is measured in decades, not months.\n",
    "\n",
    "> **Future work:** As these ETFs accumulate longer track records, this analysis should be extended with:\n",
    "> - Monthly frequency regressions (once 60+ months are available)\n",
    "> - Rolling-window analysis to assess stability of factor exposures\n",
    "> - Comparison with US-listed equivalents (e.g., AVUV, AVGV) that have longer histories\n",
    "> - Re-estimation using Global daily factors once they are updated beyond mid-2019\n",
    "> - Conditional analysis across different market regimes (bull/bear, high/low volatility)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
